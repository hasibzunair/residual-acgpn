{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0731d3d3-e15d-4570-b950-2f69996ef9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f23572-710c-4b45-b0b7-cdd8fa535ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "import datetime\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae8d03-0d83-4d4d-a08e-ff6a20ed8c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c6384-4c98-42c7-a96b-7893658ddf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13a2b81-483c-4465-9c82-3f6108c70c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages (1.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed90c3b-f877-4d3b-a6a5-c5dd6f735f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788adf7-2955-4361-a2ee-75d949d982ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10963268-54a4-4c16-817c-d8a7365025f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/uniform_all')\n",
    "SIZE=320\n",
    "NC=14\n",
    "def log(text):\n",
    "    '''Print text and save in a log file'''\n",
    "    if log_file is not None:\n",
    "        print(text, file=log_file)\n",
    "    print(text)\n",
    "    \n",
    "def generate_label_plain(inputs):\n",
    "    size = inputs.size()\n",
    "    pred_batch = []\n",
    "    for input in inputs:\n",
    "        input = input.view(1, NC, 256,192)\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_batch = pred_batch.view(size[0], 1, 256,192)\n",
    "\n",
    "    return label_batch\n",
    "\n",
    "def morpho(mask,iter):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    new=[]\n",
    "    for i in range(len(mask)):\n",
    "        tem=mask[i].squeeze().reshape(256,192,1)*255\n",
    "        tem=tem.astype(np.uint8)\n",
    "        tem=cv2.dilate(tem,kernel,iterations=iter)\n",
    "        tem=tem.astype(np.float64)\n",
    "        tem=tem.reshape(1,256,192)\n",
    "        new.append(tem.astype(np.float64)/255.0)\n",
    "    new=np.stack(new)\n",
    "    return new\n",
    "\n",
    "def generate_label_color(inputs):\n",
    "    label_batch = []\n",
    "    for i in range(len(inputs)):\n",
    "        label_batch.append(util.tensor2label(inputs[i], opt.label_nc))\n",
    "    label_batch = np.array(label_batch)\n",
    "    label_batch = label_batch * 2 - 1\n",
    "    input_label = torch.from_numpy(label_batch)\n",
    "\n",
    "    return input_label\n",
    "\n",
    "def complete_compose(img,mask,label):\n",
    "    label=label.cpu().numpy()\n",
    "    M_f=label>0\n",
    "    M_f=M_f.astype(np.int)\n",
    "    M_f=torch.FloatTensor(M_f).cuda()\n",
    "    masked_img=img*(1-mask)\n",
    "    M_c=(1-mask.cuda())*M_f\n",
    "    M_c=M_c+torch.zeros(img.shape).cuda()##broadcasting\n",
    "    return masked_img,M_c,M_f\n",
    "\n",
    "def compose(label,mask,color_mask,edge,color,noise):\n",
    "    # check=check>0\n",
    "    # print(check)\n",
    "    masked_label=label*(1-mask)\n",
    "    masked_edge=mask*edge\n",
    "    masked_color_strokes=mask*(1-color_mask)*color\n",
    "    masked_noise=mask*noise\n",
    "    return masked_label,masked_edge,masked_color_strokes,masked_noise\n",
    "\n",
    "def changearm(old_label):\n",
    "    label=old_label\n",
    "    arm1=torch.FloatTensor((data['label'].cpu().numpy()==11).astype(np.int))\n",
    "    arm2=torch.FloatTensor((data['label'].cpu().numpy()==13).astype(np.int))\n",
    "    noise=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.int))\n",
    "    label=label*(1-arm1)+arm1*4\n",
    "    label=label*(1-arm2)+arm2*4\n",
    "    label=label*(1-noise)+noise*4\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f9fe03-7f25-4974-a361-768e2c304c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "batchSize: 1\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../datasets/acgpn_data/try_on_training/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "gpu_ids: [0]\n",
      "input_nc: 3\n",
      "isTrain: True\n",
      "label_nc: 20\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_pretrain: \n",
      "lr: 0.0002\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2city\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_ganFeat_loss: False\n",
      "no_html: False\n",
      "no_lsgan: False\n",
      "no_vgg_loss: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 0\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('sample',exist_ok=True)\n",
    "opt = TrainOptions().parse()\n",
    "\n",
    "# Change to run on notebook\n",
    "opt.dataroot = \"../../datasets/acgpn_data/try_on_training/\"\n",
    "#opt.checkpoints_dir = \"../checkpoints\"\n",
    "\n",
    "\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "log_path = os.path.join(opt.checkpoints_dir, opt.name, 'log.txt')\n",
    "log_file = open(log_path, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6a4d5-d207-4678-b657-cb80505dd72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfeca58b-514d-4beb-ab58-e3a5e5893b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../datasets/acgpn_data/try_on_training/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29893871-cddc-44a9-aa62-e854ef5ab1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4fc385-40ce-4ab8-ae0c-f0675f6342e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.continue_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ad176-3e6f-4aad-bd2c-c5adb50f4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f70ebd-d47a-44ca-b3c7-5b685050576f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a080d69f-3790-4f79-93bc-4b8d220d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    log('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617767d9-4a66-486f-84f5-645583c84f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bec2e77-0516-46dc-a0e8-e379f8d62f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_epoch, epoch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63433301-b707-4816-a901-02d76c3326f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78449a53-0d06-43b2-9122-a21b79145861",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548b5ab-6f9a-4e30-a866-eda369e7b0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4d02a-bd01-4278-b9a1-fa0956c74d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46cfca2e-7203-4358-ac90-3cfc36cae37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDatasetDataLoader\n",
      "dataset [AlignedDataset] was created\n",
      "../../datasets/acgpn_data/try_on_training/train_label label\n",
      "../../datasets/acgpn_data/try_on_training/train_label label\n",
      "../../datasets/acgpn_data/try_on_training/train_img img\n",
      "../../datasets/acgpn_data/try_on_training/train_img img\n",
      "../../datasets/acgpn_data/try_on_training/train_edge edge\n",
      "../../datasets/acgpn_data/try_on_training/train_edge edge\n",
      "../../datasets/acgpn_data/try_on_training/train_mask mask\n",
      "../../datasets/acgpn_data/try_on_training/train_mask mask\n",
      "../../datasets/acgpn_data/try_on_training/train_colormask colormask\n",
      "../../datasets/acgpn_data/try_on_training/train_colormask colormask\n",
      "../../datasets/acgpn_data/try_on_training/train_color color\n",
      "../../datasets/acgpn_data/try_on_training/train_color color\n",
      "#training images = 14221\n"
     ]
    }
   ],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "log('#training images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2e20d6a-da65-4ade-9716-21e92d759899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b357131-bf0d-4028-b1a7-7caf430a649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'label_ref', 'image', 'image_ref', 'path', 'path_ref', 'edge', 'color', 'mask', 'colormask', 'pose'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9791a68-b19d-4b04-becc-686b5c736358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../datasets/acgpn_data/try_on_training/train_label/014023_0.png']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e242b3-2e79-4b85-b048-ddcd13871fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d085ee-1edf-464d-b12a-29bd54730b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ad57d7b-33eb-4891-9db2-c9c00fd685c4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81ae69-6fe1-47db-a7b2-1a7e37dd24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = None\n",
    "# model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eaaee7-ea3b-45b9-8bc1-d219da86e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "\n",
    "# display_delta = total_steps % opt.display_freq\n",
    "# print_delta = total_steps % opt.print_freq\n",
    "# save_delta = total_steps % opt.save_latest_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc439e95-e74d-48df-9e39-02ce17043a77",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91619333-9081-4a20-a07d-085e086c40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step = 0\n",
    "# from IPython.core.debugger import set_trace; set_trace()\n",
    "# step_per_batch = dataset_size / opt.batchSize\n",
    "# for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "#     epoch_start_time = time.time()\n",
    "#     if epoch != start_epoch:\n",
    "#         epoch_iter = epoch_iter % dataset_size\n",
    "\n",
    "#     for i, data in enumerate(dataset, start=epoch_iter):\n",
    "#         iter_start_time = time.time()\n",
    "\n",
    "#         total_steps += opt.batchSize\n",
    "#         epoch_iter += opt.batchSize\n",
    "\n",
    "#         # whether to collect output images\n",
    "#         #save_fake = total_steps % opt.display_freq == display_delta\n",
    "#         save_fake = True\n",
    "\n",
    "#         ##add gaussian noise channel && wash the label\n",
    "#         t_mask=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.float))\n",
    "#         data['label']=data['label']*(1-t_mask)+t_mask*4\n",
    "#         mask_clothes=torch.FloatTensor((data['label'].cpu().numpy()==4).astype(np.int))\n",
    "#         mask_fore=torch.FloatTensor((data['label'].cpu().numpy()>0).astype(np.int))\n",
    "#         img_fore=data['image']*mask_fore\n",
    "#         img_fore_wc=img_fore*mask_fore\n",
    "#         all_clothes_label=changearm(data['label'])\n",
    "#         ############## Forward Pass ######################\n",
    "#         losses, fake_image, real_image,input_label,L1_loss,style_loss,clothes_mask,warped,refined,CE_loss,rx,ry,cx,cy,rg,cg= model(Variable(data['label'].cuda()),Variable(data['edge'].cuda()),Variable(img_fore.cuda()),Variable(mask_clothes.cuda()),Variable(data['color'].cuda()),Variable(all_clothes_label.cuda()),Variable(data['image'].cuda()),Variable(data['pose'].cuda()),Variable(data['mask'].cuda())  )\n",
    "\n",
    "#         # sum per device losses\n",
    "#         losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "#         loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "#         # calculate final loss scalar\n",
    "#         loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "#         loss_G = loss_dict['G_GAN']+loss_dict.get('G_GAN_Feat',0)+loss_dict.get('G_VGG',0)+torch.mean(L1_loss+CE_loss+rx+ry+cx+cy+rg+cg)\n",
    "\n",
    "#         writer.add_scalar('loss_d', loss_D, step)\n",
    "#         writer.add_scalar('loss_g', loss_G, step)\n",
    "#         writer.add_scalar('loss_L1', torch.mean(L1_loss), step)\n",
    "#         writer.add_scalar('CE_loss', torch.mean(CE_loss), step)\n",
    "#         writer.add_scalar('rx', torch.mean(rx), step)\n",
    "#         writer.add_scalar('ry', torch.mean(ry), step)\n",
    "#         writer.add_scalar('cx', torch.mean(cx), step)\n",
    "#         writer.add_scalar('cy', torch.mean(cy), step)\n",
    "\n",
    "#         writer.add_scalar('loss_g_gan', loss_dict['G_GAN'], step)\n",
    "#         writer.add_scalar('loss_g_gan_feat', loss_dict['G_GAN_Feat'], step)\n",
    "#         writer.add_scalar('loss_g_vgg', loss_dict['G_VGG'], step)\n",
    "\n",
    "#         ############### Backward Pass ####################\n",
    "#         # update generator weights\n",
    "#         model.module.optimizer_G.zero_grad()\n",
    "#         loss_G.backward()\n",
    "#         model.module.optimizer_G.step()\n",
    "#         #\n",
    "#         # # update discriminator weights\n",
    "#         model.module.optimizer_D.zero_grad()\n",
    "#         loss_D.backward()\n",
    "#         model.module.optimizer_D.step()\n",
    "\n",
    "#         ############## Display results and errors ##########\n",
    "\n",
    "\n",
    "#         ### display output images\n",
    "#         if step % 100 == 0:\n",
    "#             a = generate_label_color(generate_label_plain(input_label)).float().cuda()\n",
    "#             b = real_image.float().cuda()\n",
    "#             c = fake_image.float().cuda()\n",
    "#             d=torch.cat([clothes_mask,clothes_mask,clothes_mask],1)\n",
    "#             e=warped\n",
    "#             f=refined\n",
    "#             combine = torch.cat([a[0],b[0],c[0],d[0],e[0],f[0]], 2).squeeze()\n",
    "#             cv_img=(combine.permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "#             writer.add_image('combine', (combine.data + 1) / 2.0, step)\n",
    "#             rgb=(cv_img*255).astype(np.uint8)\n",
    "#             bgr=cv2.cvtColor(rgb,cv2.COLOR_RGB2BGR)\n",
    "#             cv2.imwrite('sample/test'+str(step)+'.jpg',bgr)\n",
    "\n",
    "#         step += 1\n",
    "#         iter_end_time = time.time()\n",
    "#         iter_delta_time = iter_end_time - iter_start_time\n",
    "#         step_delta = (step_per_batch-step%step_per_batch) + step_per_batch*(opt.niter + opt.niter_decay-epoch)\n",
    "#         eta = iter_delta_time*step_delta\n",
    "#         eta = str(datetime.timedelta(seconds=int(eta)))\n",
    "#         time_stamp = datetime.datetime.now()\n",
    "#         now = time_stamp.strftime('%Y.%m.%d-%H:%M:%S')\n",
    "#         #print('{}:{}:[step-{}]--[loss_G-{:.6f}]--[loss_D-{:.6f}]--[ETA-{}]-[rx{}]-[ry{}]-[cx{}]-[cy{}]-[rg{}]-[cg{}]'.format(now,epoch_iter,step, loss_G, loss_D, eta,rx,ry,cx,cy,rg,cg))\n",
    "#         log('{}:{}:[step-{}]--[loss_G-{:.6f}]--[loss_D-{:.6f}]--[ETA-{}]'.format(now,epoch_iter,step, loss_G,loss_D, eta))\n",
    "\n",
    "#         ### save latest model\n",
    "#         if total_steps % opt.save_latest_freq == save_delta:\n",
    "#             log('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "#             model.module.save('latest')\n",
    "#             np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "#         # subsample dataset\n",
    "#         # for full data use 'dataset_size'\n",
    "#         if epoch_iter >= 5000:\n",
    "#             break\n",
    "\n",
    "#     # end of epoch \n",
    "#     iter_end_time = time.time()\n",
    "#     log('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "#           (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "#     ### save model for this epoch\n",
    "#     if epoch % opt.save_epoch_freq == 0:\n",
    "#         log('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "#         model.module.save('latest')\n",
    "#         model.module.save(epoch)\n",
    "#         np.savetxt(iter_path, (epoch + 1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "#     ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "#     if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "#         model.module.update_fixed_params()\n",
    "\n",
    "#     ### linearly decay learning rate after certain iterations\n",
    "#     if epoch > opt.niter:\n",
    "#         model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b674c69-0f9d-49b0-869d-7a9a226b7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac06893-3f4e-43cf-becc-35cbddae35ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
