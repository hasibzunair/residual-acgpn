{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae53153-c605-4809-b544-23d693e33385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0afa9-b824-4095-9eb6-eec292934118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9568d2-02df-44b2-a6dc-eb1370089116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "152a36eb-25c8-4509-8709-dc1c1b355ed2",
   "metadata": {},
   "source": [
    "## Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4906c2e4-4c45-472c-9773-8ca62a7ca65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Convolutional block:\n",
    "    It follows a two 3x3 convolutional layer, each followed by a batch normalization and a relu activation.\n",
    "\"\"\"\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c51ac9-184b-42d7-b426-0bdfa1b000ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Encoder block:\n",
    "    It consists of an conv_block followed by a max pooling.\n",
    "    Here the number of filters doubles and the height and width half after every block.\n",
    "\"\"\"\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f862177a-bc3e-41bc-b9f7-8ce4f2074437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Decoder block:\n",
    "    The decoder block begins with a transpose convolution, followed by a concatenation with the skip\n",
    "    connection from the encoder block. Next comes the conv_block.\n",
    "    Here the number filters decreases by half and the height and width doubles.\n",
    "\"\"\"\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052c0ff8-1e25-4674-beca-dfc40568732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        outputs = self.outputs(d4)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1732475f-bb11-4958-b12a-25744cff0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = torch.randn((2, 32, 256, 256))\n",
    "# e = encoder_block(32, 64)\n",
    "# x, p = e(inputs)\n",
    "# print(x.shape, p.shape)\n",
    "#\n",
    "# d = decoder_block(64, 32)\n",
    "# y = d(p, x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58130db-c3e4-4e0a-81f6-22141a79e105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((2, 3, 512, 512))\n",
    "model = build_unet()\n",
    "y = model(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62261d0c-483d-4c80-a3c0-443614ccbe39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb209035-c9d6-40af-bc7b-79387150a36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b962f57f-9e32-4b6c-aaf8-51596d57541c",
   "metadata": {},
   "source": [
    "## ResUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633a4bdd-6a99-41da-aaa8-305c5a070516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class batchnorm_relu(nn.Module):\n",
    "    def __init__(self, in_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(in_c)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.bn(inputs)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class residual_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Convolutional layer \"\"\"\n",
    "        self.b1 = batchnorm_relu(in_c)\n",
    "        self.c1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, stride=stride)\n",
    "        self.b2 = batchnorm_relu(out_c)\n",
    "        self.c2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        \"\"\" Shortcut Connection (Identity Mapping) \"\"\"\n",
    "        self.s = nn.Conv2d(in_c, out_c, kernel_size=1, padding=0, stride=stride)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.b1(inputs)\n",
    "        x = self.c1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.c2(x)\n",
    "        s = self.s(inputs)\n",
    "\n",
    "        skip = x + s\n",
    "        return skip\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.r = residual_block(in_c+out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.upsample(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.r(x)\n",
    "        return x\n",
    "\n",
    "class build_resunet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(3, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(inputs)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(inputs)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc75745d-51c0-4567-8d63-a92275c2118f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 192])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((1, 3, 256, 192))\n",
    "model = build_resunet()\n",
    "y = model(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d28c22-e59e-4aff-b196-549b3b92d169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8096f-3103-4f15-b474-31d26d472ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abb07d-7bd7-4999-9296-bf622925bd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b854f2f-e3db-4af2-adda-209b5195e0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45cb5794-f37a-49eb-bca2-09d6fc49ff64",
   "metadata": {},
   "source": [
    "# Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba35420-6e87-4251-9793-e318a84b1a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Refine(nn.Module):\n",
    "    def __init__(self, input_nc=37, output_nc=14):\n",
    "        super(Refine, self).__init__()\n",
    "        nl = nn.InstanceNorm2d\n",
    "        self.conv1 = nn.Sequential(*[nn.Conv2d(input_nc, 64, kernel_size=3, stride=1, padding=1), nl(64), nn.ReLU(),\n",
    "                                     nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nl(64), nn.ReLU()])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(*[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), nl(128), nn.ReLU(),\n",
    "                                     nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1), nl(128), nn.ReLU()])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv3 = nn.Sequential(*[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1), nl(256), nn.ReLU(),\n",
    "                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nl(256), nn.ReLU()])\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv4 = nn.Sequential(*[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1), nl(512), nn.ReLU(),\n",
    "                                     nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), nl(512), nn.ReLU()])\n",
    "        self.drop4 = nn.Dropout(0.5)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv5 = nn.Sequential(*[nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1), nl(1024), nn.ReLU(),\n",
    "                                     nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1), nl(1024), nn.ReLU()])\n",
    "        self.drop5 = nn.Dropout(0.5)\n",
    "\n",
    "        self.up6 = nn.Sequential(\n",
    "            *[nn.UpsamplingNearest2d(scale_factor=2), nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=1), nl(512),\n",
    "              nn.ReLU()])\n",
    "\n",
    "        self.conv6 = nn.Sequential(*[nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=1), nl(512), nn.ReLU(),\n",
    "                                     nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), nl(512), nn.ReLU()])\n",
    "        self.up7 = nn.Sequential(\n",
    "            *[nn.UpsamplingNearest2d(scale_factor=2), nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), nl(256),\n",
    "              nn.ReLU()])\n",
    "        self.conv7 = nn.Sequential(*[nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), nl(256), nn.ReLU(),\n",
    "                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nl(256), nn.ReLU()])\n",
    "\n",
    "        self.up8 = nn.Sequential(\n",
    "            *[nn.UpsamplingNearest2d(scale_factor=2), nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1), nl(128),\n",
    "              nn.ReLU()])\n",
    "\n",
    "        self.conv8 = nn.Sequential(*[nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1), nl(128), nn.ReLU(),\n",
    "                                     nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1), nl(128), nn.ReLU()])\n",
    "\n",
    "        self.up9 = nn.Sequential(\n",
    "            *[nn.UpsamplingNearest2d(scale_factor=2), nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1), nl(64),\n",
    "              nn.ReLU()])\n",
    "\n",
    "        self.conv9 = nn.Sequential(*[nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1), nl(64), nn.ReLU(),\n",
    "                                     nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nl(64), nn.ReLU(),\n",
    "                                     nn.Conv2d(64, output_nc, kernel_size=3, stride=1, padding=1)\n",
    "                                     ])\n",
    "\n",
    "    def refine(self, input):\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        conv1 = self.conv1(input)\n",
    "        pool1 = self.pool1(conv1)\n",
    "\n",
    "        conv2 = self.conv2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "\n",
    "        conv3 = self.conv3(pool2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "\n",
    "        conv4 = self.conv4(pool3)\n",
    "        drop4 = self.drop4(conv4)\n",
    "        pool4 = self.pool4(drop4)\n",
    "\n",
    "        conv5 = self.conv5(pool4)\n",
    "        drop5 = self.drop5(conv5)\n",
    "\n",
    "        up6 = self.up6(drop5)\n",
    "        conv6 = self.conv6(torch.cat([drop4, up6], 1))\n",
    "\n",
    "        up7 = self.up7(conv6)\n",
    "        conv7 = self.conv7(torch.cat([conv3, up7], 1))\n",
    "\n",
    "        up8 = self.up8(conv7)\n",
    "        conv8 = self.conv8(torch.cat([conv2, up8], 1))\n",
    "\n",
    "        up9 = self.up9(conv8)\n",
    "        conv9 = self.conv9(torch.cat([conv1, up9], 1))\n",
    "        return conv9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b430ba-0eb7-4066-a2c0-25fbf956c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(56)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     55 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 56 \u001b[0;31m        \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m        \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m     51 \u001b[0m                                     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     52 \u001b[0m                                     ])\n",
      "\u001b[1;32m     53 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     54 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrefine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     55 \u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 56 \u001b[0;31m        \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     57 \u001b[0m        \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     58 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     59 \u001b[0m        \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     60 \u001b[0m        \u001b[0mpool2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     61 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(57)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m        \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 57 \u001b[0;31m        \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  conv1.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 256, 192])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(59)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     58 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 59 \u001b[0;31m        \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m        \u001b[0mpool2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(60)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     59 \u001b[0;31m        \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 60 \u001b[0;31m        \u001b[0mpool2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(62)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     61 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 62 \u001b[0;31m        \u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m        \u001b[0mpool3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(63)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     62 \u001b[0;31m        \u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 63 \u001b[0;31m        \u001b[0mpool3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(65)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m        \u001b[0mconv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m        \u001b[0mdrop4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(66)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     65 \u001b[0;31m        \u001b[0mconv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m        \u001b[0mdrop4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m        \u001b[0mpool4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(67)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m        \u001b[0mdrop4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 67 \u001b[0;31m        \u001b[0mpool4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(69)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     68 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m        \u001b[0mconv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m        \u001b[0mdrop5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(70)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     69 \u001b[0;31m        \u001b[0mconv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 70 \u001b[0;31m        \u001b[0mdrop5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(72)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m        \u001b[0mup6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m        \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m(73)\u001b[0;36mrefine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     72 \u001b[0;31m        \u001b[0mup6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m        \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  drop4.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 32, 24])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up6.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 32, 24])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.cat([drop4, up6], 1).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 32, 24])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17701/380222981.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRefine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mup6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mup7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17701/4149168963.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mup6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mup7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comp6321/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comp6321/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((1, 37, 256, 192))\n",
    "model = None\n",
    "model = Refine()\n",
    "y = model.refine(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d24ac526-8b9e-48df-a217-eed9a8f467ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Refine(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (drop4): Dropout(p=0.5, inplace=False)\n",
       "  (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (drop5): Dropout(p=0.5, inplace=False)\n",
       "  (up6): Sequential(\n",
       "    (0): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (up7): Sequential(\n",
       "    (0): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv7): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (up8): Sequential(\n",
       "    (0): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv8): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (up9): Sequential(\n",
       "    (0): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv9): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f0531-ed4a-44b6-b52a-f3e997eec30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6b6b4-5f32-4d2f-b1c1-7dd2f1801903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e12c124-4191-4424-a0ca-53858470928c",
   "metadata": {},
   "source": [
    "## Resunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b2c06c-9bdc-4da9-a00c-778f2723ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class batchnorm_relu(nn.Module):\n",
    "    def __init__(self, in_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(in_c)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.bn(inputs)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class residual_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Convolutional layer \"\"\"\n",
    "        self.b1 = batchnorm_relu(in_c)\n",
    "        self.c1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, stride=stride)\n",
    "        self.b2 = batchnorm_relu(out_c)\n",
    "        self.c2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        \"\"\" Shortcut Connection (Identity Mapping) \"\"\"\n",
    "        self.s = nn.Conv2d(in_c, out_c, kernel_size=1, padding=0, stride=stride)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.b1(inputs)\n",
    "        x = self.c1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.c2(x)\n",
    "        s = self.s(inputs)\n",
    "\n",
    "        skip = x + s\n",
    "        return skip\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.r = residual_block(in_c+out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.upsample(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.r(x)\n",
    "        return x\n",
    "\n",
    "class Refine_ResUnet(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc=3):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(input_nc, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(37, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, output_nc, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def refine(self, input):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(input)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(input)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60301645-1c2c-419e-8f73-94ec74016b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 256, 192])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((1, 37, 256, 192))\n",
    "model = Refine_ResUnet(37, 14)\n",
    "y = model.refine(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6942406f-6b85-486e-a7f8-97d8519b49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070b582-95a1-4efc-b26a-dc832ba266de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d0f2a5-b762-4a0b-9ab0-55bf23894139",
   "metadata": {},
   "source": [
    "## Resunet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a1f888-4300-472d-92aa-9f9aaf2cf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features=64, norm_layer=nn.InstanceNorm2d): #nn.BatchNorm2d\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.relu = nn.ReLU(True)\n",
    "        if norm_layer == None:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "                norm_layer(in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "                norm_layer(in_features)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Refine_ResUnet_New(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_downs=5, ngf=32,\n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(Refine_ResUnet_New, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n",
    "\n",
    "        for i in range(num_downs - 5):\n",
    "            unet_block = ResUnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
    "        \n",
    "        self.model = unet_block\n",
    "        self.output = nn.Sequential(*[nn.Conv2d(ngf, output_nc, kernel_size=3, stride=1, padding=1)\n",
    "                                     ]) \n",
    "    def refine(self, input):\n",
    "        x = self.model(input)\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "# Defines the submodule with skip connection.\n",
    "# X -------------------identity---------------------- X\n",
    "#   |-- downsampling -- |submodule| -- upsampling --|\n",
    "class ResUnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(ResUnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=3,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        # add two resblock\n",
    "        res_downconv = [ResidualBlock(inner_nc, norm_layer), ResidualBlock(inner_nc, norm_layer)]\n",
    "        res_upconv = [ResidualBlock(outer_nc, norm_layer), ResidualBlock(outer_nc, norm_layer)]\n",
    "\n",
    "        downrelu = nn.ReLU(True)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        if norm_layer != None:\n",
    "            downnorm = norm_layer(inner_nc)\n",
    "            upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            upconv = nn.Conv2d(inner_nc * 2, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downconv, downrelu] + res_downconv\n",
    "            up = [upsample, upconv]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            upconv = nn.Conv2d(inner_nc, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downconv, downrelu] + res_downconv\n",
    "            if norm_layer == None:\n",
    "                up = [upsample, upconv, uprelu] + res_upconv\n",
    "            else:\n",
    "                up = [upsample, upconv, upnorm, uprelu] + res_upconv\n",
    "            model = down + up\n",
    "        else:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            upconv = nn.Conv2d(inner_nc*2, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            if norm_layer == None:\n",
    "                down = [downconv, downrelu] + res_downconv\n",
    "                up = [upsample, upconv, uprelu] + res_upconv\n",
    "            else:\n",
    "                down = [downconv, downnorm, downrelu] + res_downconv\n",
    "                up = [upsample, upconv, upnorm, uprelu] + res_upconv\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5716fdc-e069-4b68-b7c6-aa77cc83ce31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Refine_ResUnet_New(\n",
       "  (model): ResUnetSkipConnectionBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(37, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): ResidualBlock(\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ResUnetSkipConnectionBlock(\n",
       "        (model): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): ResidualBlock(\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualBlock(\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): ResUnetSkipConnectionBlock(\n",
       "            (model): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): ResidualBlock(\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (block): Sequential(\n",
       "                  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (4): ResidualBlock(\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (block): Sequential(\n",
       "                  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (5): ResUnetSkipConnectionBlock(\n",
       "                (model): Sequential(\n",
       "                  (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                  (3): ResidualBlock(\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (block): Sequential(\n",
       "                      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (2): ReLU(inplace=True)\n",
       "                      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (4): ResidualBlock(\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (block): Sequential(\n",
       "                      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (2): ReLU(inplace=True)\n",
       "                      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (5): ResUnetSkipConnectionBlock(\n",
       "                    (model): Sequential(\n",
       "                      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (1): ReLU(inplace=True)\n",
       "                      (2): ResidualBlock(\n",
       "                        (relu): ReLU(inplace=True)\n",
       "                        (block): Sequential(\n",
       "                          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                          (2): ReLU(inplace=True)\n",
       "                          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                      )\n",
       "                      (3): ResidualBlock(\n",
       "                        (relu): ReLU(inplace=True)\n",
       "                        (block): Sequential(\n",
       "                          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                          (2): ReLU(inplace=True)\n",
       "                          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                      )\n",
       "                      (4): Upsample(scale_factor=2.0, mode=nearest)\n",
       "                      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (7): ReLU(inplace=True)\n",
       "                      (8): ResidualBlock(\n",
       "                        (relu): ReLU(inplace=True)\n",
       "                        (block): Sequential(\n",
       "                          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                          (2): ReLU(inplace=True)\n",
       "                          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                      )\n",
       "                      (9): ResidualBlock(\n",
       "                        (relu): ReLU(inplace=True)\n",
       "                        (block): Sequential(\n",
       "                          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                          (2): ReLU(inplace=True)\n",
       "                          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (6): Upsample(scale_factor=2.0, mode=nearest)\n",
       "                  (7): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (9): ReLU(inplace=True)\n",
       "                  (10): ResidualBlock(\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (block): Sequential(\n",
       "                      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (2): ReLU(inplace=True)\n",
       "                      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (11): ResidualBlock(\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (block): Sequential(\n",
       "                      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (2): ReLU(inplace=True)\n",
       "                      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (6): Upsample(scale_factor=2.0, mode=nearest)\n",
       "              (7): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (9): ReLU(inplace=True)\n",
       "              (10): ResidualBlock(\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (block): Sequential(\n",
       "                  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (11): ResidualBlock(\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (block): Sequential(\n",
       "                  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (7): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (9): ReLU(inplace=True)\n",
       "          (10): ResidualBlock(\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (11): ResidualBlock(\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Conv2d(32, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Refine_ResUnet_New(37, 14)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722509fd-fdd7-4745-bd8c-dafbc6070420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddcf4c40-363b-490c-91eb-17c322d8c755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 256, 192])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((1, 37, 256, 192))\n",
    "model = Refine_ResUnet_New(37, 14)\n",
    "y = model.refine(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f33a2-a221-4da2-94f6-8a42dd92c3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
