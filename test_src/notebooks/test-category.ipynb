{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85066f14-24cf-4596-827d-d1ad83fb049c",
   "metadata": {},
   "source": [
    "## Test config on easy, medium and hard and all images\n",
    "\n",
    "Computes SSIM and FID scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2f59d4-2cfb-4a40-9562-3d54f5c87d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c27a4a-2cd5-4e55-ac51-848259cb2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537c6d9-977b-4464-88e3-fdb97750e732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981b276-7b8c-42de-a5d7-d66b1ae05a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48218e-3ce7-43b5-a12f-7d87d51a2808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48fa7a1-4b78-455e-8616-2e47beddc4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af84dc47-d388-4fa6-af70-4d10520739d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/G1G2')\n",
    "SIZE=320\n",
    "NC=14\n",
    "def generate_label_plain(inputs):\n",
    "    size = inputs.size()\n",
    "    pred_batch = []\n",
    "    for input in inputs:\n",
    "        input = input.view(1, NC, 256,192)\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_batch = pred_batch.view(size[0], 1, 256,192)\n",
    "\n",
    "    return label_batch\n",
    "\n",
    "def generate_label_color(inputs):\n",
    "    label_batch = []\n",
    "    for i in range(len(inputs)):\n",
    "        label_batch.append(util.tensor2label(inputs[i], opt.label_nc))\n",
    "    label_batch = np.array(label_batch)\n",
    "    label_batch = label_batch * 2 - 1\n",
    "    input_label = torch.from_numpy(label_batch)\n",
    "\n",
    "    return input_label\n",
    "def complete_compose(img,mask,label):\n",
    "    label=label.cpu().numpy()\n",
    "    M_f=label>0\n",
    "    M_f=M_f.astype(np.int)\n",
    "    M_f=torch.FloatTensor(M_f).cuda()\n",
    "    masked_img=img*(1-mask)\n",
    "    M_c=(1-mask.cuda())*M_f\n",
    "    M_c=M_c+torch.zeros(img.shape).cuda()##broadcasting\n",
    "    return masked_img,M_c,M_f\n",
    "\n",
    "def compose(label,mask,color_mask,edge,color,noise):\n",
    "    # check=check>0\n",
    "    # print(check)\n",
    "    masked_label=label*(1-mask)\n",
    "    masked_edge=mask*edge\n",
    "    masked_color_strokes=mask*(1-color_mask)*color\n",
    "    masked_noise=mask*noise\n",
    "    return masked_label,masked_edge,masked_color_strokes,masked_noise\n",
    "def changearm(old_label):\n",
    "    label=old_label\n",
    "    arm1=torch.FloatTensor((data['label'].cpu().numpy()==11).astype(np.int))\n",
    "    arm2=torch.FloatTensor((data['label'].cpu().numpy()==13).astype(np.int))\n",
    "    noise=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.int))\n",
    "    label=label*(1-arm1)+arm1*4\n",
    "    label=label*(1-arm2)+arm2*4\n",
    "    label=label*(1-noise)+noise*4\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f40d-a2fd-49b6-bd8a-4dcd86691b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6430f1e-63ab-4c22-abbd-e7543751273f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0beec7f2-e1c7-49cc-a990-d29dadf24ead",
   "metadata": {},
   "source": [
    "## Select configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e3cedc-8d0e-41be-93e9-02684083809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "batchSize: 1\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "datapairs: test_pairs.txt\n",
      "dataroot: ../datasets/acgpn_data/try_on_testing/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "gpu_ids: [0]\n",
      "input_nc: 3\n",
      "isTrain: True\n",
      "label_nc: 20\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_pretrain: ./checkpoints/label2city\n",
      "lr: 0.0002\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2city\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_ganFeat_loss: False\n",
      "no_html: False\n",
      "no_lsgan: False\n",
      "no_vgg_loss: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: test\n",
      "pool_size: 0\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n"
     ]
    }
   ],
   "source": [
    "## Load models\n",
    "exp_name = \"resunet_g1\"\n",
    "model_dir = \"../../train_src/checkpoints/\"\n",
    "\n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "opt.load_pretrain = model_dir+exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35260c-7690-4d80-ad98-80ddeb3d42df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfc458-a1be-4063-9448-4922816a69ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "521b2386-c3f2-4337-9a2b-8ac3ad5df582",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.datapairs = \"medium_same.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c93a1cc4-e17e-4e4c-bbfd-ba4af3179181",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480773d8-f4a6-4076-8e9f-31b25291b824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcb975-e401-481b-8271-abf049bfa486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7acb6-05ab-46ae-8f20-d625c1f739c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72939acf-271f-4178-94ab-641c11393e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to tryon\n",
    "os.makedirs('../tryons_category/{}/{}'.format(exp_name, category),exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee49cf6-6cac-4bfe-b4a5-0a20e824dbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901ec3e-7c3a-4381-9cfc-8c22175ca2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40dd6928-c5c4-4625-a603-89320bcb040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../train_src/checkpoints/resunet_g1\n"
     ]
    }
   ],
   "source": [
    "# Select test data\n",
    "opt.dataroot = \"../../datasets/acgpn_data/try_on_testing/\"\n",
    "\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "# Check models used\n",
    "print(opt.load_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cb772e4-a823-4a60-aa43-2b734fa0c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1df327ac-e988-4a12-912c-7cc09787187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01bb4cf1-84c2-438e-b0fa-c4da4e95d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDatasetDataLoader\n",
      "dataset [AlignedDataset] was created\n",
      "../../datasets/acgpn_data/try_on_testing/test_label label\n",
      "../../datasets/acgpn_data/try_on_testing/test_label label\n",
      "../../datasets/acgpn_data/try_on_testing/test_img img\n",
      "../../datasets/acgpn_data/try_on_testing/test_img img\n",
      "../../datasets/acgpn_data/try_on_testing/test_edge edge\n",
      "../../datasets/acgpn_data/try_on_testing/test_edge edge\n",
      "../../datasets/acgpn_data/try_on_testing/test_mask mask\n",
      "../../datasets/acgpn_data/try_on_testing/test_mask mask\n",
      "../../datasets/acgpn_data/try_on_testing/test_colormask colormask\n",
      "../../datasets/acgpn_data/try_on_testing/test_colormask colormask\n",
      "../../datasets/acgpn_data/try_on_testing/test_color color\n",
      "../../datasets/acgpn_data/try_on_testing/test_color color\n",
      "# Inference images = 514\n"
     ]
    }
   ],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('# Inference images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486a158-e0bd-4d19-b4c4-fb4e7ba130e3",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96712e78-2fc0-419a-a7e9-0d607cb8db9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest_net_U.pth\n",
      "latest_net_G1.pth\n",
      "latest_net_G2.pth\n",
      "latest_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a5a19c9-76ce-403c-ae23-57c29c27b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2ecfbbf-2637-498a-881a-bcfee7e6f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dummy = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0cae560-00ef-4465-a56b-77382695887a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'label_ref', 'image', 'image_ref', 'path', 'path_ref', 'edge', 'color', 'mask', 'colormask', 'pose', 'name'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cefd13d-005a-450f-b2f9-ac840a23bc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../../datasets/acgpn_data/try_on_testing/test_label/005533_0.png'],\n",
       " ['../../datasets/acgpn_data/try_on_testing/test_label/012137_0.png'],\n",
       " ['005533_0.jpg'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummy['path'], data_dummy['path_ref'], data_dummy['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81e03fc5-18c4-4e70-a655-49a5230f90a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 192])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummy['mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4453bb3f-ae57-4e84-9df2-b8101d926cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 192])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummy['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63af784-401a-4c90-981c-57091f57e995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6b48237-c448-4d85-88b5-634523d5d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from PIL import Image, ImageDraw\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8b39e8d-1393-4c55-a20b-78543b6b2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = cv2.imread(data_dummy['path'][0], -1)\n",
    "# B = cv2.imread(data_dummy['path_ref'][0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35dab868-4c37-49d9-b74b-336ad491d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_stack = np.hstack((A, B))\n",
    "# plt.imshow(img_stack)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e57ab5e8-e401-4edb-b707-dd4886e5672e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 201)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_epoch, opt.niter + opt.niter_decay + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a82a5d29-a3ed-4dae-9c57-188330e35503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f5052b4-b166-4d86-a9bc-ab8051932b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/home/hz/anaconda3/envs/comp6321/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1 / 200 \t Time Taken: 48 sec\n"
     ]
    }
   ],
   "source": [
    "step = 0 \n",
    "ssims = []\n",
    "\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "        \n",
    "    # iterate over the dataset\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        #save_fake = total_steps % opt.display_freq == display_delta\n",
    "        save_fake = True\n",
    "\n",
    "        ##add gaussian noise channel\n",
    "        ## wash the label\n",
    "        t_mask = torch.FloatTensor((data['label'].cpu().numpy() == 7).astype(np.float))\n",
    "        #\n",
    "        # data['label'] = data['label'] * (1 - t_mask) + t_mask * 4\n",
    "        mask_clothes = torch.FloatTensor((data['label'].cpu().numpy() == 4).astype(np.int))\n",
    "        mask_fore = torch.FloatTensor((data['label'].cpu().numpy() > 0).astype(np.int))\n",
    "        img = data['image'].float().cuda()\n",
    "        img_fore = data['image'] * mask_fore\n",
    "        img_fore_wc = img_fore * mask_fore\n",
    "        all_clothes_label = changearm(data['label'])\n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        losses, fake_image, real_image, input_label,L1_loss,style_loss,clothes_mask,CE_loss,rgb,alpha= model(Variable(data['label'].cuda()),\n",
    "                                                                                                             Variable(data['edge'].cuda()),\n",
    "                                                                                                             Variable(img_fore.cuda()),\n",
    "                                                                                                             Variable(mask_clothes.cuda()),\n",
    "                                                                                                             Variable(data['color'].cuda()),\n",
    "                                                                                                             Variable(all_clothes_label.cuda()),\n",
    "                                                                                                             Variable(data['image'].cuda()),\n",
    "                                                                                                             Variable(data['pose'].cuda()) ,\n",
    "                                                                                                             Variable(data['image'].cuda()) ,\n",
    "                                                                                                             Variable(mask_fore.cuda()))\n",
    "                                            \n",
    "        \n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN']+torch.mean(CE_loss)#loss_dict.get('G_GAN_Feat',0)+torch.mean(L1_loss)+loss_dict.get('G_VGG',0)\n",
    "\n",
    "        writer.add_scalar('loss_d', loss_D, step)\n",
    "        writer.add_scalar('loss_g', loss_G, step)\n",
    "        writer.add_scalar('loss_CE', torch.mean(CE_loss), step)\n",
    "        writer.add_scalar('loss_g_gan', loss_dict['G_GAN'], step)\n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "\n",
    "        \n",
    "        ### display output images\n",
    "        a = generate_label_color(generate_label_plain(input_label)).float().cuda()\n",
    "        b = real_image.float().cuda()\n",
    "        c = fake_image.float().cuda()\n",
    "        d=torch.cat([clothes_mask,clothes_mask,clothes_mask],1)\n",
    "        combine = torch.cat([a[0],d[0],b[0],c[0],rgb[0]], 2).squeeze()\n",
    "        # combine=c[0].squeeze()\n",
    "        cv_img=(combine.permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "        if step % 1 == 0:\n",
    "            writer.add_image('combine', (combine.data + 1) / 2.0, step)\n",
    "            rgb=(cv_img*255).astype(np.uint8)\n",
    "            bgr=cv2.cvtColor(rgb,cv2.COLOR_RGB2BGR)\n",
    "            n=str(step)+'.jpg'\n",
    "            \n",
    "            #cv2.imwrite('../samples/'+exp_name+'/'+data['name'][0],bgr)\n",
    "            \n",
    "            #########################################\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            \n",
    "            # Save tryon images\n",
    "            fake_i =(fake_image[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "            fake_i=(fake_i*255).astype(np.uint8)\n",
    "            fake_i=cv2.cvtColor(fake_i,cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            cv2.imwrite('../tryons_category/'+exp_name+'/'+category+'/'+data['name'][0],fake_i)\n",
    "            #########################################\n",
    "            \n",
    "        step += 1\n",
    "        #print(step)\n",
    "        \n",
    "        \n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        \n",
    "        ##################################################\n",
    "        # Compute SSIM scores\n",
    "        def norm(tensor_list):\n",
    "            mins = tensor_list.min()\n",
    "            maxs = tensor_list.max()\n",
    "            normalized_data = (tensor_list - mins) / (maxs - mins)\n",
    "            return normalized_data\n",
    "        \n",
    "        # Normalize image to [0-1]\n",
    "        real_norm = norm(img)\n",
    "        fake_norm = norm(fake_image)\n",
    "\n",
    "        score = pytorch_ssim.ssim(real_norm, fake_norm)\n",
    "        score = score.item()\n",
    "        #print(\"SSIM for {}-----:\".format(step), score)\n",
    "        ssims.append(score)\n",
    "        ##################################################\n",
    "        \n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            # print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            # model.module.save('latest')\n",
    "            # np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "            pass\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "\n",
    "        # Debug\n",
    "#         if i == 10:\n",
    "#             print(\"Exiting loop.\")\n",
    "#             #i = 0\n",
    "#             break\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    break\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        # np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1911ad8-0ec6-47e9-bbe3-937333ab14c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56256e45-b5f3-4259-a3df-e6c52297a0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ecfbc5f-6d23-4ee7-99e1-0576146422e4",
   "metadata": {},
   "source": [
    "# Compute SSIM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6663df66-6302-4142-9d0b-e5ec0fd69992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM score: 0.8254\n"
     ]
    }
   ],
   "source": [
    "score = np.array(ssims).mean()\n",
    "print(\"SSIM score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d47d62-a80b-461a-8493-1fc7678198ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25f216-1a1f-4edc-b77e-b30ce337c51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5f028c1-c797-4117-87f5-f09806c618d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score > 0.8273"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110c101-71c8-474b-bac3-407a87466550",
   "metadata": {},
   "source": [
    "# Compute FID scores\n",
    "(ref: -4.0183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b753c6-cef3-4610-a5d7-4c61abba01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pytorch_fid '../tryons_category/resunet_g1/all_same' '../../datasets/acgpn_data/try_on_testing/test_img'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed3d588-fd66-4712-86c3-513d22d61b61",
   "metadata": {},
   "source": [
    "| Model  | Test all SSIM (higher) | Test easy SSIM (higher) | Test medium SSIM (higher)| Test hard SSIM (higher)| Test FID (lower) |\n",
    "| ------------- | ------------- | ------------- | ------------- | ------------- |------------- |\n",
    "| ACGPN Paper  | 0.8669 | - |- |- |14.107 |\n",
    "| ACGPN All (reimplemented acgpn)  | 0.8727 | - |- |- |12.868 |\n",
    "| ACGPN 5000  | 0.8231 | 0.8311 |0.8214 |0.8044 |26.167 |\n",
    "| ResUnet 32filt, BN (resunet_g1, ngf=32) | **0.8273** | **0.8356** | **0.8254** | **0.8083** | **23.032** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca10b8-b58c-4593-be70-24dfb24b9e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f570c96-0b93-4e0a-8ee0-9acd86416ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
