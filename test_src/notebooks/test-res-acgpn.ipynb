{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85066f14-24cf-4596-827d-d1ad83fb049c",
   "metadata": {},
   "source": [
    "## Test Residual ACGPN\n",
    "\n",
    "This notebook runs inference on VITON test set as well as computes SSIM and FID scores for the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f59d4-2cfb-4a40-9562-3d54f5c87d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fa7a1-4b78-455e-8616-2e47beddc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")\n",
    "\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "\n",
    "import pytorch_ssim\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683dee1-4429-4117-9cbb-b7200dd31f11",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84dc47-d388-4fa6-af70-4d10520739d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/G1G2')\n",
    "SIZE=320\n",
    "NC=14\n",
    "def generate_label_plain(inputs):\n",
    "    size = inputs.size()\n",
    "    pred_batch = []\n",
    "    for input in inputs:\n",
    "        input = input.view(1, NC, 256,192)\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_batch = pred_batch.view(size[0], 1, 256,192)\n",
    "\n",
    "    return label_batch\n",
    "\n",
    "def generate_label_color(inputs):\n",
    "    label_batch = []\n",
    "    for i in range(len(inputs)):\n",
    "        label_batch.append(util.tensor2label(inputs[i], opt.label_nc))\n",
    "    label_batch = np.array(label_batch)\n",
    "    label_batch = label_batch * 2 - 1\n",
    "    input_label = torch.from_numpy(label_batch)\n",
    "\n",
    "    return input_label\n",
    "def complete_compose(img,mask,label):\n",
    "    label=label.cpu().numpy()\n",
    "    M_f=label>0\n",
    "    M_f=M_f.astype(np.int)\n",
    "    M_f=torch.FloatTensor(M_f).cuda()\n",
    "    masked_img=img*(1-mask)\n",
    "    M_c=(1-mask.cuda())*M_f\n",
    "    M_c=M_c+torch.zeros(img.shape).cuda()##broadcasting\n",
    "    return masked_img,M_c,M_f\n",
    "\n",
    "def compose(label,mask,color_mask,edge,color,noise):\n",
    "    # check=check>0\n",
    "    # print(check)\n",
    "    masked_label=label*(1-mask)\n",
    "    masked_edge=mask*edge\n",
    "    masked_color_strokes=mask*(1-color_mask)*color\n",
    "    masked_noise=mask*noise\n",
    "    return masked_label,masked_edge,masked_color_strokes,masked_noise\n",
    "def changearm(old_label):\n",
    "    label=old_label\n",
    "    arm1=torch.FloatTensor((data['label'].cpu().numpy()==11).astype(np.int))\n",
    "    arm2=torch.FloatTensor((data['label'].cpu().numpy()==13).astype(np.int))\n",
    "    noise=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.int))\n",
    "    label=label*(1-arm1)+arm1*4\n",
    "    label=label*(1-arm2)+arm2*4\n",
    "    label=label*(1-noise)+noise*4\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beec7f2-e1c7-49cc-a990-d29dadf24ead",
   "metadata": {},
   "source": [
    "## Select configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3cedc-8d0e-41be-93e9-02684083809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Name configuration\n",
    "exp_name = \"resacgpn\"\n",
    "model_dir = \"../../train_src/checkpoints/\"\n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "opt.load_pretrain = model_dir+exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a1cc4-e17e-4e4c-bbfd-ba4af3179181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pairs_same.txt is used to compute SSIM and FID scores\n",
    "# it is the in-shop cloth version, that is the reference person is wearing the same target cloth\n",
    "# can also use easy_same.txt, medium_same.txt and hard_same.txt to compute metrics for those cases.\n",
    "\n",
    "data_dict = {\"test_pairs_same.txt\" : \"all_same\",\n",
    "             \"easy_same.txt\" : \"easy\",\n",
    "             \"medium_same.txt\" : \"medium\",\n",
    "             \"hard_same.txt\" : \"hard\"}\n",
    "\n",
    "opt.datapairs = \"test_pairs_same.txt\" \n",
    "category = data_dict[\"test_pairs_same.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd6928-c5c4-4625-a603-89320bcb040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to tryon\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, category),exist_ok=True)\n",
    "\n",
    "# Select test data\n",
    "opt.dataroot = \"../../datasets/acgpn_data/try_on_testing/\"\n",
    "\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "# Check models used\n",
    "print(opt.load_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb772e4-a823-4a60-aa43-2b734fa0c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0\n",
    "    \n",
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10   \n",
    "    \n",
    "    \n",
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('# Inference images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486a158-e0bd-4d19-b4c4-fb4e7ba130e3",
   "metadata": {},
   "source": [
    "### Load trained configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96712e78-2fc0-419a-a7e9-0d607cb8db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d83bd-5c85-4b40-9e5f-f1b86efc4f9a",
   "metadata": {},
   "source": [
    "### Inference on test set\n",
    "\n",
    "Colab demo for single image is [here](https://github.com/hasibzunair/residual-acgpn-demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5052b4-b166-4d86-a9bc-ab8051932b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq\n",
    "\n",
    "start_epoch, opt.niter + opt.niter_decay + 1\n",
    "\n",
    "step = 0 \n",
    "ssims = []\n",
    "\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "        \n",
    "    # iterate over the dataset\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        #save_fake = total_steps % opt.display_freq == display_delta\n",
    "        save_fake = True\n",
    "\n",
    "        ##add gaussian noise channel\n",
    "        ## wash the label\n",
    "        t_mask = torch.FloatTensor((data['label'].cpu().numpy() == 7).astype(np.float))\n",
    "        #\n",
    "        # data['label'] = data['label'] * (1 - t_mask) + t_mask * 4\n",
    "        mask_clothes = torch.FloatTensor((data['label'].cpu().numpy() == 4).astype(np.int))\n",
    "        mask_fore = torch.FloatTensor((data['label'].cpu().numpy() > 0).astype(np.int))\n",
    "        img = data['image'].float().cuda()\n",
    "        img_fore = data['image'] * mask_fore\n",
    "        img_fore_wc = img_fore * mask_fore\n",
    "        all_clothes_label = changearm(data['label'])\n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        \n",
    "        losses, fake_image, real_image, input_label,L1_loss,style_loss,clothes_mask,CE_loss,rgb,alpha, gt_clothes_mask, warp_tcw, warp_tcr,  = model(Variable(data['label'].cuda()),\n",
    "                                                                                                             Variable(data['edge'].cuda()),\n",
    "                                                                                                             Variable(img_fore.cuda()),\n",
    "                                                                                                             Variable(mask_clothes.cuda()),\n",
    "                                                                                                             Variable(data['color'].cuda()),\n",
    "                                                                                                             Variable(all_clothes_label.cuda()),\n",
    "                                                                                                             Variable(data['image'].cuda()),\n",
    "                                                                                                             Variable(data['pose'].cuda()) ,\n",
    "                                                                                                             Variable(data['image'].cuda()) ,\n",
    "                                                                                                             Variable(mask_fore.cuda()))\n",
    "                                            \n",
    "        \n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN']+torch.mean(CE_loss)#loss_dict.get('G_GAN_Feat',0)+torch.mean(L1_loss)+loss_dict.get('G_VGG',0)\n",
    "\n",
    "        writer.add_scalar('loss_d', loss_D, step)\n",
    "        writer.add_scalar('loss_g', loss_G, step)\n",
    "        writer.add_scalar('loss_CE', torch.mean(CE_loss), step)\n",
    "        writer.add_scalar('loss_g_gan', loss_dict['G_GAN'], step)\n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "\n",
    "        \n",
    "        ### display output images\n",
    "        a = generate_label_color(generate_label_plain(input_label)).float().cuda()\n",
    "        b = real_image.float().cuda()\n",
    "        c = fake_image.float().cuda()\n",
    "        d=torch.cat([clothes_mask,clothes_mask,clothes_mask],1)\n",
    "        combine = torch.cat([a[0],d[0],b[0],c[0],rgb[0]], 2).squeeze()\n",
    "        # combine=c[0].squeeze()\n",
    "        cv_img=(combine.permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "        if step % 1 == 0:\n",
    "            writer.add_image('combine', (combine.data + 1) / 2.0, step)\n",
    "            rgb=(cv_img*255).astype(np.uint8)\n",
    "            bgr=cv2.cvtColor(rgb,cv2.COLOR_RGB2BGR)\n",
    "            n=str(step)+'.jpg'\n",
    "            \n",
    "            #cv2.imwrite('../samples/'+exp_name+'/'+data['name'][0],bgr)\n",
    "            \n",
    "            #########################################\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            \n",
    "            # Save tryon images\n",
    "            fake_i =(fake_image[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "            fake_i=(fake_i*255).astype(np.uint8)\n",
    "            fake_i=cv2.cvtColor(fake_i,cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            cv2.imwrite('../outputs/'+exp_name+'/'+category+'/'+data['name'][0],fake_i)\n",
    "            #########################################\n",
    "            \n",
    "            if category == \"all\":\n",
    "                # Save body part segmentations\n",
    "                seg =(a[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                seg=(seg*255).astype(np.uint8)\n",
    "                seg=cv2.cvtColor(seg,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/bpmask/'+data['name'][0],seg)\n",
    "                \n",
    "                # Save warped cloth region segmentations\n",
    "                cmask =(clothes_mask[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                cmask=(cmask*255).astype(np.uint8)\n",
    "                cmask=cv2.cvtColor(cmask,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/wcrmask/'+data['name'][0],cmask)\n",
    "                \n",
    "                # Save gt segmentations\n",
    "                gt_cmask =(gt_clothes_mask[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                gt_cmask=(gt_cmask*255).astype(np.uint8)\n",
    "                gt_cmask=cv2.cvtColor(gt_cmask,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/gt_clothes_mask/'+data['name'][0],gt_cmask)\n",
    "                \n",
    "                # Save target cloth\n",
    "                cloth =(data['color'][0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                cloth=(cloth*255).astype(np.uint8)\n",
    "                cloth=cv2.cvtColor(cloth,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/clothes/'+data['name'][0],cloth)\n",
    "                \n",
    "                # Save warped cloth\n",
    "                warpc =(warp_tcw[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                warpc=(warpc*255).astype(np.uint8)\n",
    "                warpc=cv2.cvtColor(warpc,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/warped_clothes/'+data['name'][0],warpc)\n",
    "                \n",
    "                # Save warped cloth refined via unet\n",
    "                warpcref =(warp_tcr[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                warpcref=(warpcref*255).astype(np.uint8)\n",
    "                warpcref=cv2.cvtColor(warpcref,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/warped_clothes_ref/'+data['name'][0],warpcref)\n",
    "\n",
    "            \n",
    "        step += 1\n",
    "        #print(step)\n",
    "        \n",
    "        ##################################################\n",
    "        # Compute SSIM scores\n",
    "        def norm(tensor_list):\n",
    "            mins = tensor_list.min()\n",
    "            maxs = tensor_list.max()\n",
    "            normalized_data = (tensor_list - mins) / (maxs - mins)\n",
    "            return normalized_data\n",
    "        \n",
    "        # Normalize image to [0-1]\n",
    "        real_norm = norm(img)\n",
    "        fake_norm = norm(fake_image)\n",
    "\n",
    "        score = pytorch_ssim.ssim(real_norm, fake_norm)\n",
    "        score = score.item()\n",
    "        #print(\"SSIM for {}-----:\".format(step), score)\n",
    "        ssims.append(score)\n",
    "        ##################################################\n",
    "        \n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            # print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            # model.module.save('latest')\n",
    "            # np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "            pass\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "\n",
    "#         # Debug\n",
    "#         if i == 10:\n",
    "#             print(\"Exiting loop.\")\n",
    "#             #i = 0\n",
    "#             break\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    break\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        # np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecfbc5f-6d23-4ee7-99e1-0576146422e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute SSIM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663df66-6302-4142-9d0b-e5ec0fd69992",
   "metadata": {},
   "outputs": [],
   "source": [
    "if category == \"all\":\n",
    "    print(\"No SSIM!\") \n",
    "else:\n",
    "    score = np.array(ssims).mean()\n",
    "    print(\"SSIM score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110c101-71c8-474b-bac3-407a87466550",
   "metadata": {},
   "source": [
    "### Compute FID scores\n",
    "\n",
    "In case the cell below does not run (due to memory error), please restart the notebook and simply run this cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b753c6-cef3-4610-a5d7-4c61abba01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FID between generated tryon and ground truth\n",
    "!python -m pytorch_fid '../outputs/resacgpn/all_same' '../../datasets/acgpn_data/try_on_testing/test_img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca10b8-b58c-4593-be70-24dfb24b9e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
