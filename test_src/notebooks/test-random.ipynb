{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08843315-3609-4c67-b1f3-29922d30ed85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test on random cloth pairs\n",
    "\n",
    "For quality evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f59d4-2cfb-4a40-9562-3d54f5c87d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c27a4a-2cd5-4e55-ac51-848259cb2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537c6d9-977b-4464-88e3-fdb97750e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb15d2-798b-4f32-a2e8-9241a8393910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fa7a1-4b78-455e-8616-2e47beddc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "from options.train_options import TrainOptions\n",
    "from data.data_loader_random import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84dc47-d388-4fa6-af70-4d10520739d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/G1G2')\n",
    "SIZE=320\n",
    "NC=14\n",
    "def generate_label_plain(inputs):\n",
    "    size = inputs.size()\n",
    "    pred_batch = []\n",
    "    for input in inputs:\n",
    "        input = input.view(1, NC, 256,192)\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_batch = pred_batch.view(size[0], 1, 256,192)\n",
    "\n",
    "    return label_batch\n",
    "\n",
    "def generate_label_color(inputs):\n",
    "    label_batch = []\n",
    "    for i in range(len(inputs)):\n",
    "        label_batch.append(util.tensor2label(inputs[i], opt.label_nc))\n",
    "    label_batch = np.array(label_batch)\n",
    "    label_batch = label_batch * 2 - 1\n",
    "    input_label = torch.from_numpy(label_batch)\n",
    "\n",
    "    return input_label\n",
    "def complete_compose(img,mask,label):\n",
    "    label=label.cpu().numpy()\n",
    "    M_f=label>0\n",
    "    M_f=M_f.astype(np.int)\n",
    "    M_f=torch.FloatTensor(M_f).cuda()\n",
    "    masked_img=img*(1-mask)\n",
    "    M_c=(1-mask.cuda())*M_f\n",
    "    M_c=M_c+torch.zeros(img.shape).cuda()##broadcasting\n",
    "    return masked_img,M_c,M_f\n",
    "\n",
    "def compose(label,mask,color_mask,edge,color,noise):\n",
    "    # check=check>0\n",
    "    # print(check)\n",
    "    masked_label=label*(1-mask)\n",
    "    masked_edge=mask*edge\n",
    "    masked_color_strokes=mask*(1-color_mask)*color\n",
    "    masked_noise=mask*noise\n",
    "    return masked_label,masked_edge,masked_color_strokes,masked_noise\n",
    "def changearm(old_label):\n",
    "    label=old_label\n",
    "    arm1=torch.FloatTensor((data['label'].cpu().numpy()==11).astype(np.int))\n",
    "    arm2=torch.FloatTensor((data['label'].cpu().numpy()==13).astype(np.int))\n",
    "    noise=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.int))\n",
    "    label=label*(1-arm1)+arm1*4\n",
    "    label=label*(1-arm2)+arm2*4\n",
    "    label=label*(1-noise)+noise*4\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f40d-a2fd-49b6-bd8a-4dcd86691b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6430f1e-63ab-4c22-abbd-e7543751273f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0beec7f2-e1c7-49cc-a990-d29dadf24ead",
   "metadata": {},
   "source": [
    "## Select configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3cedc-8d0e-41be-93e9-02684083809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load models\n",
    "exp_name = \"resunet_g1\"\n",
    "model_dir = \"../../train_src/checkpoints/\"\n",
    "\n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "opt.load_pretrain = model_dir+exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3f22c-0da7-4790-ba9a-4b56e5a2c235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abf770-bc45-4742-a229-43e36c84f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72939acf-271f-4178-94ab-641c11393e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to img,segmentation,tryons\n",
    "#os.makedirs('../samples_random/{}'.format(exp_name),exist_ok=True)\n",
    "\n",
    "# Path to tryon\n",
    "os.makedirs('../tryons_random/{}/{}'.format(exp_name, mode),exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd6928-c5c4-4625-a603-89320bcb040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test data\n",
    "opt.dataroot = \"../../datasets/acgpn_data/try_on_testing/\"\n",
    "\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "# Check models used\n",
    "print(opt.load_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb772e4-a823-4a60-aa43-2b734fa0c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df327ac-e988-4a12-912c-7cc09787187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb4cf1-84c2-438e-b0fa-c4da4e95d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('# Inference images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486a158-e0bd-4d19-b4c4-fb4e7ba130e3",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96712e78-2fc0-419a-a7e9-0d607cb8db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a19c9-76ce-403c-ae23-57c29c27b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ecfbbf-2637-498a-881a-bcfee7e6f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cae560-00ef-4465-a56b-77382695887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76fc90-bde9-4e7d-9cb3-561d8a40222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy['path'], data_dummy['path_ref'], data_dummy['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e03fc5-18c4-4e70-a655-49a5230f90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy['mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453bb3f-ae57-4e84-9df2-b8101d926cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63af784-401a-4c90-981c-57091f57e995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b48237-c448-4d85-88b5-634523d5d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from PIL import Image, ImageDraw\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b39e8d-1393-4c55-a20b-78543b6b2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = cv2.imread(data_dummy['path'][0], -1)\n",
    "# B = cv2.imread(data_dummy['path_ref'][0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dab868-4c37-49d9-b74b-336ad491d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_stack = np.hstack((A, B))\n",
    "# plt.imshow(img_stack)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ab5e8-e401-4edb-b707-dd4886e5672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch, opt.niter + opt.niter_decay + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a5d29-a3ed-4dae-9c57-188330e35503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5052b4-b166-4d86-a9bc-ab8051932b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0 \n",
    "ssims = []\n",
    "\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "        \n",
    "    # iterate over the dataset\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        #save_fake = total_steps % opt.display_freq == display_delta\n",
    "        save_fake = True\n",
    "\n",
    "        ##add gaussian noise channel\n",
    "        ## wash the label\n",
    "        t_mask = torch.FloatTensor((data['label'].cpu().numpy() == 7).astype(np.float))\n",
    "        #\n",
    "        # data['label'] = data['label'] * (1 - t_mask) + t_mask * 4\n",
    "        mask_clothes = torch.FloatTensor((data['label'].cpu().numpy() == 4).astype(np.int))\n",
    "        mask_fore = torch.FloatTensor((data['label'].cpu().numpy() > 0).astype(np.int))\n",
    "        img = data['image'].float().cuda()\n",
    "        img_fore = data['image'] * mask_fore\n",
    "        img_fore_wc = img_fore * mask_fore\n",
    "        all_clothes_label = changearm(data['label'])\n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        losses, fake_image, real_image, input_label,L1_loss,style_loss,clothes_mask,CE_loss,rgb,alpha= model(Variable(data['label'].cuda()),\n",
    "                                                                                                             Variable(data['edge'].cuda()),\n",
    "                                                                                                             Variable(img_fore.cuda()),\n",
    "                                                                                                             Variable(mask_clothes.cuda()),\n",
    "                                                                                                             Variable(data['color'].cuda()),\n",
    "                                                                                                             Variable(all_clothes_label.cuda()),\n",
    "                                                                                                             Variable(data['image'].cuda()),\n",
    "                                                                                                             Variable(data['pose'].cuda()) ,\n",
    "                                                                                                             Variable(data['image'].cuda()) ,\n",
    "                                                                                                             Variable(mask_fore.cuda()))\n",
    "                                            \n",
    "        \n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN']+torch.mean(CE_loss)#loss_dict.get('G_GAN_Feat',0)+torch.mean(L1_loss)+loss_dict.get('G_VGG',0)\n",
    "\n",
    "        writer.add_scalar('loss_d', loss_D, step)\n",
    "        writer.add_scalar('loss_g', loss_G, step)\n",
    "        writer.add_scalar('loss_CE', torch.mean(CE_loss), step)\n",
    "        writer.add_scalar('loss_g_gan', loss_dict['G_GAN'], step)\n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "\n",
    "        \n",
    "        ### display output images\n",
    "        a = generate_label_color(generate_label_plain(input_label)).float().cuda()\n",
    "        b = real_image.float().cuda()\n",
    "        c = fake_image.float().cuda()\n",
    "        d=torch.cat([clothes_mask,clothes_mask,clothes_mask],1)\n",
    "        combine = torch.cat([a[0],d[0],b[0],c[0],rgb[0]], 2).squeeze()\n",
    "        # combine=c[0].squeeze()\n",
    "        cv_img=(combine.permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "        if step % 1 == 0:\n",
    "            writer.add_image('combine', (combine.data + 1) / 2.0, step)\n",
    "            rgb=(cv_img*255).astype(np.uint8)\n",
    "            bgr=cv2.cvtColor(rgb,cv2.COLOR_RGB2BGR)\n",
    "            n=str(step)+'.jpg'\n",
    "            \n",
    "            #cv2.imwrite('../samples_random/'+exp_name+'/'+data['name'][0],bgr)\n",
    "            \n",
    "            #########################################\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            \n",
    "            # Save tryon images\n",
    "            fake_i =(fake_image[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "            fake_i=(fake_i*255).astype(np.uint8)\n",
    "            fake_i=cv2.cvtColor(fake_i,cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            cv2.imwrite('../tryons_random/'+exp_name+'/'+mode+'/'+data['name'][0],fake_i)\n",
    "            #########################################\n",
    "\n",
    "        step += 1\n",
    "        #print(step)\n",
    "        \n",
    "        \n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        \n",
    "        ##################################################\n",
    "#         # Compute SSIM scores\n",
    "#         def norm(tensor_list):\n",
    "#             mins = tensor_list.min()\n",
    "#             maxs = tensor_list.max()\n",
    "#             normalized_data = (tensor_list - mins) / (maxs - mins)\n",
    "#             return normalized_data\n",
    "        \n",
    "#         # Normalize image to [0-1]\n",
    "#         real_norm = norm(img)\n",
    "#         fake_norm = norm(fake_image)\n",
    "\n",
    "#         score = pytorch_ssim.ssim(real_norm, fake_norm)\n",
    "#         score = score.item()\n",
    "#         #print(\"SSIM for {}-----:\".format(step), score)\n",
    "#         ssims.append(score)\n",
    "        ##################################################\n",
    "        \n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            # print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            # model.module.save('latest')\n",
    "            # np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "            pass\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "\n",
    "        # Debug\n",
    "#         if i == 10:\n",
    "#             print(\"Exiting loop.\")\n",
    "#             #i = 0\n",
    "#             break\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    break\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        # np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cdbd1-326c-436f-a3cc-e8e8685ba656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b955f74-6950-456f-a37f-0ac065d7751f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01986e-41a2-4c4c-90cf-d13e1efb1e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f462644-375c-4786-966b-9e398651d9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
